# -*- coding: utf-8 -*-
"""Voyager_Extension.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19W9uCLLzhpt29CFw8evmzpsWSrYLZtHj
"""

"""
Voyager_Extension.py
Enhanced Voyager extension with:
- Comparative multi-optimizer capture & overlay visualization
- Streamlit web interface to run experiments interactively
- Utilities to save/load trajectories and export metric tables

Usage:
- To use as a module: import functions and call `compare_and_visualize(...)`.
- To run the web UI: `streamlit run Voyager_Extension.py` and open the local URL.

Notes:
- This file intentionally keeps the CIFAR demo small by default; change max_steps for longer runs.
- For reproducible comparisons we reinitialize model weights from the same random seed/state.
"""

from typing import List, Dict, Optional, Tuple
import time
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision
import torchvision.transforms as transforms
from sklearn.decomposition import PCA
import pandas as pd

# Optional imports: UMAP, PHATE, ripser
try:
    import umap
except Exception:
    umap = None
try:
    import phate
except Exception:
    phate = None
try:
    from ripser import ripser
    from persim import plot_diagrams
except Exception:
    ripser = None
    plot_diagrams = None

import plotly.graph_objs as go
from plotly.subplots import make_subplots

# Streamlit for web UI (optional)
try:
    import streamlit as st
    has_streamlit = True
except Exception:
    has_streamlit = False

# -------------------------
# (Existing utilities — flatten/capture/embed/metrics/plot)
# -------------------------

def flatten_params(model: nn.Module) -> np.ndarray:
    with torch.no_grad():
        parts = [p.detach().cpu().numpy().ravel() for p in model.parameters()]
        if len(parts)==0:
            return np.array([])
        return np.concatenate(parts)


def capture_trajectory(model: nn.Module, optimizer, criterion, dataloader: DataLoader, device: torch.device,
                       steps_per_snapshot: int=100, max_steps: Optional[int]=None) -> Dict:
    model.to(device)
    model.train()
    params_list = []
    losses = []
    grad_norms = []
    steps = []
    step = 0
    epoch = 0
    while True:
        epoch += 1
        for xb, yb in dataloader:
            xb, yb = xb.to(device), yb.to(device)
            optimizer.zero_grad()
            out = model(xb)
            loss = criterion(out, yb)
            loss.backward()
            optimizer.step()

            step += 1
            if step % steps_per_snapshot == 0:
                params_list.append(flatten_params(model))
                losses.append(loss.item())
                gn = 0.0
                for p in model.parameters():
                    if p.grad is not None:
                        gn += p.grad.detach().cpu().norm().item()**2
                grad_norms.append(np.sqrt(gn))
                steps.append(step)
            if max_steps is not None and step >= max_steps:
                break
        if max_steps is not None and step >= max_steps:
            break
        if max_steps is None:
            break
    return {
        'params': np.vstack(params_list) if len(params_list)>0 else np.zeros((0,0)),
        'losses': np.array(losses),
        'grad_norms': np.array(grad_norms),
        'steps': np.array(steps)
    }


def path_length(coords: np.ndarray) -> float:
    if coords.shape[0] < 2:
        return 0.0
    diffs = coords[1:] - coords[:-1]
    return np.sqrt((diffs**2).sum(axis=1)).sum()


def mean_step_norm(coords: np.ndarray) -> float:
    if coords.shape[0] < 2:
        return 0.0
    diffs = coords[1:] - coords[:-1]
    return np.sqrt((diffs**2).sum(axis=1)).mean()


def curvature_estimate(coords: np.ndarray) -> float:
    if coords.shape[0] < 3:
        return 0.0
    v1 = coords[1:-1] - coords[:-2]
    v2 = coords[2:] - coords[1:-1]
    nv1 = np.linalg.norm(v1, axis=1)
    nv2 = np.linalg.norm(v2, axis=1)
    mask = (nv1 > 1e-12) & (nv2 > 1e-12)
    angles = np.zeros_like(nv1)
    dot = (v1[mask]*v2[mask]).sum(axis=1)
    cosang = np.clip(dot / (nv1[mask]*nv2[mask]), -1.0, 1.0)
    angles_masked = np.arccos(cosang)
    angles[mask] = angles_masked
    return angles.mean()


def embed_trajectory(params_array: np.ndarray, method: str='pca', dim: int=3, random_state: int=0, fit_transform_obj: Optional[object]=None) -> Tuple[np.ndarray, object]:
    if params_array.size == 0:
        return np.zeros((0, dim)), None
    if fit_transform_obj is not None:
        coords = fit_transform_obj.transform(params_array)
        return coords, fit_transform_obj
    if method == 'pca' or (method!='umap' and umap is None and phate is None):
        pca = PCA(n_components=dim, random_state=random_state)
        coords = pca.fit_transform(params_array)
        return coords, pca
    if method == 'umap' and umap is not None:
        reducer = umap.UMAP(n_components=dim, random_state=random_state)
        return reducer.fit_transform(params_array), reducer
    if method == 'phate' and phate is not None:
        p = phate.PHATE(n_components=dim, random_state=random_state)
        return p.fit_transform(params_array), p
    pca = PCA(n_components=dim, random_state=random_state)
    coords = pca.fit_transform(params_array)
    return coords, pca


def plot_3d_trajectory(coords: np.ndarray, losses: np.ndarray, steps: Optional[np.ndarray]=None, title: str="Trajectory", save_html: Optional[str]=None):
    T = coords.shape[0]
    dim = coords.shape[1]
    if dim == 2:
        z = np.zeros(T)
    else:
        z = coords[:,2]
    x = coords[:,0]
    y = coords[:,1]
    text = [f"step: {int(s)} | loss: {float(l):.4f}" for s,l in zip(steps if steps is not None else range(T), losses)]

    fig = go.Figure(
        data=[go.Scatter3d(x=x, y=y, z=z, mode='lines+markers', marker=dict(size=4, color=losses, colorscale='Viridis', colorbar=dict(title='loss')), text=text)],
        layout=go.Layout(title=title, scene=dict(xaxis=dict(title='x'), yaxis=dict(title='y'), zaxis=dict(title='z')))
    )

    frames = []
    for t in range(T):
        frame = go.Frame(data=[go.Scatter3d(x=x[:t+1], y=y[:t+1], z=z[:t+1], mode='lines+markers', marker=dict(size=4, color=losses[:t+1], colorscale='Viridis'))], name=str(t))
        frames.append(frame)
    fig.frames = frames
    steps_slider = [dict(method='animate', args=[[str(k)], dict(mode='immediate', frame=dict(duration=100, redraw=True), transition=dict(duration=0))], label=str(k)) for k in range(T)]
    sliders = [dict(active=0, pad={'t':50}, steps=steps_slider)]
    fig.update_layout(updatemenus=[dict(type='buttons', showactive=False, y=0, x=0.1, xanchor='right', yanchor='top', pad={'t':60}, buttons=[dict(label='Play', method='animate', args=[None, dict(frame=dict(duration=200, redraw=True), fromcurrent=True, transition=dict(duration=0))])])], sliders=sliders)

    if save_html is not None:
        fig.write_html(save_html)
    return fig

# -------------------------
# CIFAR-10 experiment example (small, for demonstration)
# -------------------------

def get_cifar10_loaders(batch_size=128, num_workers=2):
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))
    ])
    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)
    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
    testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)
    return trainloader, testloader

class TinyCNN(nn.Module):
    def __init__(self, num_classes=10):
        super().__init__()
        self.relu = nn.ReLU()
        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
        self.pool = nn.MaxPool2d(2,2)

        # Dynamically calculate the flattened size
        with torch.no_grad():
            dummy_input = torch.zeros(1, 3, 32, 32) # Assuming 32x32 input (CIFAR-10)
            x = self.relu(self.conv1(dummy_input))
            x = self.pool(self.relu(self.conv2(x)))
            flattened_size = x.view(1, -1).size(1)


        self.fc1 = nn.Linear(flattened_size, 256)
        self.fc2 = nn.Linear(256, num_classes)


    def forward(self, x):
        x = self.relu(self.conv1(x))
        x = self.pool(self.relu(self.conv2(x)))
        x = x.view(x.size(0), -1)
        x = self.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# -------------------------
# Comparative utilities
# -------------------------

def make_optimizer(name: str, params, lr: float=0.01):
    name = name.lower()
    if name == 'sgd':
        return optim.SGD(params, lr=lr, momentum=0.9)
    if name == 'adam':
        return optim.Adam(params, lr=lr)
    if name == 'rmsprop':
        return optim.RMSprop(params, lr=lr)
    # default
    return optim.SGD(params, lr=lr, momentum=0.9)


def compare_optimizers(model_constructor, optimizer_names: List[str], dataloader: DataLoader, device: Optional[torch.device]=None,
                       steps_per_snapshot: int=50, max_steps: int=500, seed: int=42) -> Dict:
    """Run the same model initialization for multiple optimizers and capture trajectories.
    Returns dict: {opt_name: traj_dict}
    """
    if device is None:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    # create a base model and capture its state for reproducible restarts
    base_model = model_constructor()
    base_state = base_model.state_dict()

    results = {}
    criterion = nn.CrossEntropyLoss()

    for name in optimizer_names:
        # re-instantiate and load base state so all optimizers start from same weights
        model = model_constructor()
        model.load_state_dict(base_state)
        opt = make_optimizer(name, model.parameters(), lr=0.01)
        traj = capture_trajectory(model, opt, criterion, dataloader, device, steps_per_snapshot=steps_per_snapshot, max_steps=max_steps)
        results[name] = traj
    return results


def embed_multiple_trajectories(traj_dict: Dict[str, Dict], method: str='pca', dim: int=3) -> Tuple[Dict[str, np.ndarray], object]:
    """Fit a single embedding on the concatenated parameter snapshots so trajectories share coordinates.
    Returns mapping name->coords and the fitted transform object.
    """
    # collect all params
    all_params = []
    keys = []
    for k,v in traj_dict.items():
        if v['params'].size == 0:
            continue
        all_params.append(v['params'])
        keys.append(k)
    if len(all_params)==0:
        return {}, None
    concat = np.vstack(all_params)
    coords_all, transformer = embed_trajectory(concat, method=method, dim=dim)
    # split back
    out = {}
    idx = 0
    for k in keys:
        n = traj_dict[k]['params'].shape[0]
        out[k] = coords_all[idx:idx+n]
        idx += n
    return out, transformer


def overlay_plot_3d(multi_coords: Dict[str, np.ndarray], traj_dict: Dict[str, Dict], title: str='Optimizer comparison', save_html: Optional[str]=None) -> go.Figure:
    fig = go.Figure()
    palette = ['blue', 'red', 'green', 'orange', 'purple', 'brown']
    i = 0
    for name, coords in multi_coords.items():
        losses = traj_dict[name]['losses']
        steps = traj_dict[name]['steps']
        T = coords.shape[0]
        if T==0:
            continue
        x = coords[:,0]
        y = coords[:,1]
        z = coords[:,2] if coords.shape[1]>2 else np.zeros(T)
        fig.add_trace(go.Scatter3d(x=x, y=y, z=z, mode='lines+markers', name=name,
                                   marker=dict(size=4, color=losses, colorscale='Viridis', showscale=(i==0), colorbar=dict(title='loss')),
                                   line=dict(width=2, color=palette[i%len(palette)]), text=[f"{name} step {s}" for s in steps]))
        i += 1
    fig.update_layout(title=title, scene=dict(xaxis=dict(title='x'), yaxis=dict(title='y'), zaxis=dict(title='z')))
    if save_html is not None:
        fig.write_html(save_html)
    return fig


def compute_metrics_table(multi_coords: Dict[str, np.ndarray], traj_dict: Dict[str, Dict]) -> pd.DataFrame:
    rows = []
    for name, coords in multi_coords.items():
        if coords.shape[0]==0:
            rows.append({'optimizer': name, 'path_length': np.nan, 'mean_step': np.nan, 'curvature': np.nan, 'final_loss': np.nan})
            continue
        pl = path_length(coords)
        ms = mean_step_norm(coords)
        curv = curvature_estimate(coords)
        final_loss = float(traj_dict[name]['losses'][-1]) if traj_dict[name]['losses'].size>0 else np.nan
        rows.append({'optimizer': name, 'path_length': pl, 'mean_step': ms, 'curvature': curv, 'final_loss': final_loss})
    df = pd.DataFrame(rows).set_index('optimizer')
    return df

# -------------------------
# High level convenience: run comparison and produce plot + metrics
# -------------------------

def compare_and_visualize(optimizer_names: List[str], method: str='pca', steps_per_snapshot: int=50, max_steps: int=500, device: Optional[torch.device]=None):
    if device is None:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    trainloader, _ = get_cifar10_loaders(batch_size=128)
    model_constructor = lambda: TinyCNN()
    trajs = compare_optimizers(model_constructor, optimizer_names, trainloader, device=device, steps_per_snapshot=steps_per_snapshot, max_steps=max_steps)
    multi_coords, transformer = embed_multiple_trajectories(trajs, method=method, dim=3)
    fig = overlay_plot_3d(multi_coords, trajs, title='Optimizer Comparison')
    metrics = compute_metrics_table(multi_coords, trajs)
    return {
        'trajs': trajs,
        'coords': multi_coords,
        'fig': fig,
        'metrics': metrics,
        'transformer': transformer
    }

# -------------------------
# Streamlit app
# -------------------------

def run_streamlit_app():
    if not has_streamlit:
        raise RuntimeError('Streamlit not installed. Install with `pip install streamlit`')
    st.set_page_config(layout='wide', page_title='Voyager - Optimizer Comparison')
    st.title('Voyager: Optimizer Trajectory Comparison')

    st.sidebar.header('Experiment controls')
    opts = st.sidebar.multiselect('Optimizers (choose 2-4)', ['SGD','Adam','RMSProp'], default=['SGD','Adam'])
    steps_per_snapshot = st.sidebar.slider('Steps per snapshot', min_value=1, max_value=200, value=50)
    max_steps = st.sidebar.slider('Max training steps', min_value=50, max_value=2000, value=500, step=50)
    method = st.sidebar.selectbox('Embedding method', ['pca'], index=0)

    if st.sidebar.button('Run comparison'):
        with st.spinner('Running experiments — this may take a few minutes depending on max_steps'):
            out = compare_and_visualize([o.lower() for o in opts], method=method, steps_per_snapshot=steps_per_snapshot, max_steps=max_steps)
        st.success('Run complete')
        st.subheader('Metrics')
        st.dataframe(out['metrics'])
        st.subheader('Trajectory overlay')
        st.plotly_chart(out['fig'], use_container_width=True)
        # allow download
        csv = out['metrics'].to_csv().encode('utf-8')
        st.download_button('Download metrics CSV', data=csv, file_name='voyager_metrics.csv', mime='text/csv')

# -------------------------
# If run as script use streamlit app entrypoint
# -------------------------
if __name__ == '__main__':
    # If user executed `python Voyager_Extension.py` directly, print quick instructions
    print('''This module provides `compare_and_visualize` and a Streamlit app.
To run the Streamlit web UI:
    pip install streamlit
    streamlit run Voyager_Extension.py

Or import compare_and_visualize() in a notebook to run experiments programmatically.''')